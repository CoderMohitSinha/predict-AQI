{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import datetime\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "from predict_aqi.multi_city_model import (\n",
    "    load_and_clean_locations_near_airlocation,\n",
    "    generate_AQI_inputs_and_outputs,\n",
    "    generate_predictions_two_step,\n",
    "    generate_baseline_predictions,\n",
    "    cut_off_end_split_function\n",
    ")\n",
    "\n",
    "\n",
    "def generate_errors_dict(df, indices_ahead_to_predict_range, pred_col_suffix, pred_col_prefix=\"{}_ahead\"):\n",
    "    '''\n",
    "    Calculates the mean absolute error for the pred_col for each in indices_ahead_to_predict_range.\n",
    "    Returns a dictionary with format:\n",
    "    {'2_ahead': 123.4, '6_ahead': 234.5, '10_ahead': 345.6, ...}\n",
    "    '''\n",
    "    error_dict = {}\n",
    "    for index_ahead_to_predict in indices_ahead_to_predict_range:\n",
    "        pred_col = \"{}_{}\".format(\n",
    "            pred_col_prefix.format(index_ahead_to_predict),\n",
    "            pred_col_suffix\n",
    "        )\n",
    "\n",
    "        error_dict['{}_ahead'.format(index_ahead_to_predict)] = 300 * mean_absolute_error(\n",
    "            df['{}_ahead_AQI'.format(index_ahead_to_predict)],\n",
    "            df[pred_col]\n",
    "        )\n",
    "    return error_dict\n",
    "\n",
    "\n",
    "def generate_errors_rows(df,\n",
    "                         indices_ahead_to_predict_range,\n",
    "                         number_of_nearby_locations_to_use,\n",
    "                         first_cells_of_row):\n",
    "    error_rows = []\n",
    "\n",
    "    # generate error results rows for the final predictions on this iteration\n",
    "    errors_dict = generate_errors_dict(df, indices_ahead_to_predict_range, 'pred')\n",
    "    errow_row = list(itertools.chain(\n",
    "        first_cells_of_row,\n",
    "        ['final', errors_dict]\n",
    "    ))\n",
    "    error_rows.append(errow_row)\n",
    "\n",
    "    # generate error results rows for all the first step predictions on this iteration\n",
    "    for location_number in range(1, number_of_nearby_locations_to_use + 1):\n",
    "        pred_col_suffix = \"loc_{}_first_step_pred\".format(location_number)\n",
    "        errors_dict = generate_errors_dict(df, indices_ahead_to_predict_range, pred_col_suffix)\n",
    "        errow_row = list(itertools.chain(\n",
    "            first_cells_of_row,\n",
    "            ['first_step_loc_{}'.format(location_number), errors_dict]\n",
    "        ))\n",
    "        error_rows.append(errow_row)\n",
    "\n",
    "    return error_rows\n",
    "\n",
    "\n",
    "def append_row(df, row):\n",
    "    df.loc[df.shape[0]] = row\n",
    "\n",
    "\n",
    "def test_hyperparams_on_airlocation(\n",
    "        airlocation_id,\n",
    "        indices_ahead_to_predict_range,\n",
    "        list_of_indices_behind_to_use_range,\n",
    "        list_of_number_of_nearby_locations_to_use,\n",
    "        list_of_hidden_layer_sizes,\n",
    "        list_of_alphas):\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    # load, align, and clean the data from db\n",
    "    max_locations_needed = max(list_of_number_of_nearby_locations_to_use)\n",
    "    df, airlocation_ids, continuous_time_series = load_and_clean_locations_near_airlocation(\n",
    "        airlocation_id, 50, max_locations_needed\n",
    "    )\n",
    "\n",
    "    # generate inputs and target outputs for the model\n",
    "    df, continuous_time_series, input_columns, output_columns = generate_AQI_inputs_and_outputs(\n",
    "        df,\n",
    "        continuous_time_series,\n",
    "        indices_ahead_to_predict_range,\n",
    "        max(list_of_indices_behind_to_use_range, key=lambda a: len(list(a))),\n",
    "        max_locations_needed\n",
    "    )\n",
    "\n",
    "    city_specific_input_columns = filter(lambda col: 'loc' in col, input_columns)\n",
    "    other_input_columns = list(set(input_columns) ^ set(city_specific_input_columns))\n",
    "\n",
    "    results_df = pd.DataFrame(columns=[\n",
    "        'indices_behind_to_use_range',\n",
    "        'number_of_nearby_locations_to_use',\n",
    "        'hidden_layer_sizes',\n",
    "        'alpha',\n",
    "        'airlocation_id',\n",
    "        'nearby_airlocation_ids',\n",
    "        # one of: 'final', 'first_step_loc_x' (where x is an int), 'baseline'\n",
    "        'prediction_type',\n",
    "        # error results dictionary with format:\n",
    "        # {'2_ahead': 123.4, '6_ahead': 234.5, '10_ahead': 345.6, ...}\n",
    "        'error_results'\n",
    "    ])\n",
    "\n",
    "    # for each hyperparameter\n",
    "    for indices_behind_to_use_range in list_of_indices_behind_to_use_range:\n",
    "        for number_of_nearby_locations_to_use in list_of_number_of_nearby_locations_to_use:\n",
    "            for hidden_layer_sizes in list_of_hidden_layer_sizes:\n",
    "                for alpha in list_of_alphas:\n",
    "\n",
    "                    # train model and make predictions\n",
    "                    locations = ['loc_{}'.format(str(i))\n",
    "                                 for i in range(1, number_of_nearby_locations_to_use + 1)]\n",
    "\n",
    "                    regressor_params = {'alpha': alpha, 'hidden_layer_sizes': hidden_layer_sizes}\n",
    "                    first_step_regressors = [MLPRegressor(**regressor_params)\n",
    "                                             for i in locations]\n",
    "                    second_step_regressors = [MLPRegressor(**regressor_params)\n",
    "                                              for i in indices_ahead_to_predict_range]\n",
    "\n",
    "                    this_iteration_df = df.copy(deep=True)\n",
    "                    this_iteration_df = generate_predictions_two_step(\n",
    "                        this_iteration_df,\n",
    "                        other_input_columns,\n",
    "                        output_columns,\n",
    "                        cut_off_end_split_function,\n",
    "                        locations,\n",
    "                        first_step_regressors,\n",
    "                        second_step_regressors,\n",
    "                        indices_ahead_to_predict_range,\n",
    "                        indices_behind_to_use_range,\n",
    "                        \"ahead_pred\",\n",
    "                        False\n",
    "                    )\n",
    "\n",
    "                    # calculate and store the errors\n",
    "                    first_cells_of_error_row = [\n",
    "                        indices_behind_to_use_range,\n",
    "                        number_of_nearby_locations_to_use,\n",
    "                        hidden_layer_sizes,\n",
    "                        alpha,\n",
    "                        airlocation_id,\n",
    "                        airlocation_ids\n",
    "                    ]\n",
    "                    error_results_rows = generate_errors_rows(\n",
    "                        this_iteration_df,\n",
    "                        indices_ahead_to_predict_range,\n",
    "                        number_of_nearby_locations_to_use,\n",
    "                        first_cells_of_error_row\n",
    "                    )\n",
    "\n",
    "                    for error_results_row in error_results_rows:\n",
    "                        append_row(results_df, error_results_row)\n",
    "\n",
    "                    del this_iteration_df\n",
    "                    \n",
    "    # Finally, get error results for the baseline predictions once for the location\n",
    "    df = generate_baseline_predictions(df, ['{}_ahead_AQI'.format(i) for i in indices_ahead_to_predict_range])\n",
    "    baseline_errors_dict = {}\n",
    "    for index_ahead_to_predict in indices_ahead_to_predict_range:\n",
    "        pred_col = \"{}_ahead_baseline_pred\".format(index_ahead_to_predict)\n",
    "        df[pred_col] = df[pred_col].apply(lambda x: x / 300)\n",
    "        baseline_errors_dict['{}_ahead'.format(index_ahead_to_predict)] = 300 * mean_absolute_error(\n",
    "            df['{}_ahead_AQI'.format(index_ahead_to_predict)],\n",
    "            df[pred_col]\n",
    "        )\n",
    "    append_row(\n",
    "        results_df, \n",
    "        [None, None, None, None, airlocation_id, airlocation_ids, 'baseline', baseline_errors_dict]\n",
    "    )\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    iteration_count = len(list_of_indices_behind_to_use_range) * \\\n",
    "                      len(list_of_number_of_nearby_locations_to_use) * \\\n",
    "                      len(list_of_hidden_layer_sizes) * \\\n",
    "                      len(list_of_alphas)\n",
    "    print(\n",
    "        \"Trying {} hyperparameter combinations took {} seconds\".format(\n",
    "            iteration_count,\n",
    "            (end - start).total_seconds()\n",
    "        )\n",
    "    )\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices ahead to predict range: [2, 13, 24, 35, 46]\n\nHyper-parameters:\n420 different combinations, will take approx 42.0 minutes.\nList of alphas: [0.001, 0.0005, 0.0001, 5e-05]\nList of hidden layer sizes [(24,), (100,), (100, 10)]\nList of indices behind to use range: [range(0, 1, 2), range(0, 9, 2), range(0, 17, 2), range(0, 25, 2), range(0, 33, 2), range(0, 41, 2), range(0, 49, 2)]\nList of number of nearby locations to use: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "MAX_INDEX = 48\n",
    "MAX_NUMBER_OF_CITIES_TO_USE = 5\n",
    "\n",
    "list_of_alphas = [0.001, 0.0005, 0.0001, 0.00005]\n",
    "list_of_hidden_layer_sizes = [(24,), (100,), (100, 10)]\n",
    "indices_ahead_to_predict_range = range(2, MAX_INDEX + 1, 11)\n",
    "list_of_indices_behind_to_use_range = [range(0, i + 1, 2) for i in range(0, 49, 8)]\n",
    "list_of_number_of_nearby_locations_to_use = list(range(1, 6))\n",
    "\n",
    "print(\"Indices ahead to predict range: {}\".format(str(list(indices_ahead_to_predict_range))))\n",
    "\n",
    "print(\"\\nHyper-parameters:\")\n",
    "combinations = len(list_of_alphas) * \\\n",
    "    len(list_of_hidden_layer_sizes) * \\\n",
    "    len(list_of_indices_behind_to_use_range) * \\\n",
    "    len(list_of_number_of_nearby_locations_to_use)\n",
    "print(\"{} different combinations, will take approx {} minutes.\".format(\n",
    "    combinations, combinations / 10\n",
    "))\n",
    "print(\"List of alphas: {}\".format(str(list_of_alphas)))\n",
    "print(\"List of hidden layer sizes {}\".format(str(list_of_hidden_layer_sizes)))\n",
    "print(\"List of indices behind to use range: {}\".format(str(list_of_indices_behind_to_use_range)))\n",
    "print(\"List of number of nearby locations to use: {}\".format(str(list_of_number_of_nearby_locations_to_use)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/predict_aqi/transform_data.py:125: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  new_df['is_dirty'] = new_df[output_columns].apply(lambda x: any(map(np.isnan, x)), axis=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying 420 hyperparameter combinations took 3009.450012 seconds\n"
     ]
    }
   ],
   "source": [
    "from predict_aqi.load_data import load_nearby_locations\n",
    "\n",
    "for airlocation_id in range(977, 978):\n",
    "    nearby_locations = load_nearby_locations(1160, 50)\n",
    "    if len(nearby_locations) < 5:\n",
    "        continue\n",
    "    nearby_location_ids = [l[0] for l in nearby_locations]\n",
    "    results_df = test_hyperparams_on_airlocation(\n",
    "        airlocation_id,\n",
    "        indices_ahead_to_predict_range,\n",
    "        list_of_indices_behind_to_use_range,\n",
    "        list_of_number_of_nearby_locations_to_use,\n",
    "        list_of_hidden_layer_sizes,\n",
    "        list_of_alphas\n",
    "    )\n",
    "    results_df.to_csv('predict_aqi/results_data/{}.csv'.format(airlocation_id))\n",
    "    del results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}